{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'corenlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bfa79e72c499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcorenlp\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'corenlp'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import corenlp as core\n",
    "from sklearn.metrics import classification_report\n",
    "from functools import reduce\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def isValid(tag):\n",
    "    return (tag == \"B-PER\" or tag == \"I-PER\") or (tag == \"B-ORG\" or tag == \"I-ORG\") or (\n",
    "        tag == \"B-LOC\" or tag == \"I-LOC\") or (tag == \"B-DATE\" or tag == \"I-DATE\") or (\n",
    "               tag == \"B-PERC\" or tag == \"I-PERC\") or (tag == \"B-MONEY\" or tag == \"I-MONEY\") or (\n",
    "               tag == \"B-TIME\" or tag == \"I-TIME\")\n",
    "\n",
    "\n",
    "def writeToFile(file_name, list_of_lists):\n",
    "    with open(file_name, \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(list_of_lists)\n",
    "\n",
    "\n",
    "tag_to_label = {'O': 0,\n",
    "                'B-DATE': 1, 'I-DATE': 1, 'DATE': 1,\n",
    "                'B-LOC': 2, 'I-LOC': 2, 'LOCATION': 2,\n",
    "                'B-MONEY': 3, 'I-MONEY': 3, 'MONEY': 3,\n",
    "                'B-ORG': 4, 'I-ORG': 4, 'ORGANIZATION': 4,\n",
    "                'B-PERC': 5, 'I-PERC': 5, 'PERCENT': 5,\n",
    "                'B-PER': 6, 'I-PER': 6, 'PERSON': 6,\n",
    "                'B-TIME': 7, 'I-TIME': 7, 'TIME': 7}\n",
    "\n",
    "labels = ['others', 'date', 'location', 'money', 'organization', 'percent', 'person', 'time']\n",
    "\n",
    "sentences = []\n",
    "sentence = \"\"\n",
    "entities = \"\"\n",
    "\n",
    "Y_true = [[]]\n",
    "Y_pred = [[]]\n",
    "\n",
    "y_true_val = []\n",
    "y_pred_val = []\n",
    "actual_tokens = []\n",
    "with open(sys.argv[1], encoding='ISO-8859-1') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    client = core.CoreNLPClient(annotators=\"tokenize ssplit pos lemma ner\".split())\n",
    "\n",
    "    for row in reader:\n",
    "        if row[20] == \"__START1__\" and sentence != \"\":\n",
    "            # with core.CoreNLPClient(annotators=\"tokenize ssplit pos lemma ner\".split()) as client:\n",
    "            ann = client.annotate(sentence)\n",
    "            tokens = ann.sentence[0].token\n",
    "            if (len(tokens) != len(actual_tokens)):\n",
    "                predTokens = {}\n",
    "                for token in tokens:\n",
    "                    predTokens[token.originalText] = token.ner\n",
    "                for token in actual_tokens:\n",
    "                    y_pred_val.append(tag_to_label.get(predTokens.get(token, \"O\"), 0))\n",
    "\n",
    "                    # print(y_pred_val)\n",
    "            else:\n",
    "                for i in range(0, len(tokens)):\n",
    "                    y_pred_val.append(tag_to_label.get(tokens[i].ner, 0))\n",
    "\n",
    "            # sentences.append(\"\\\"\" + sentence + \"\\\"\" + entities)\n",
    "            Y_true.append(np.array(y_true_val))\n",
    "            Y_pred.append(np.array(y_pred_val))\n",
    "            y_true_val = []\n",
    "            y_pred_val = []\n",
    "            actual_tokens = []\n",
    "            entities = \"\"\n",
    "            sentence = \"\"\n",
    "        word = row[23]\n",
    "        actual_tokens.append(word)\n",
    "        tag = row[24].upper()\n",
    "        y_true_val.append(tag_to_label.get(tag, 0))\n",
    "\n",
    "        sentence = sentence + \" \" + word\n",
    "        if (isValid(tag)):\n",
    "            entities = entities + \",\" + word + \",\" + tag\n",
    "\n",
    "writeToFile(\"outputYTrue.csv\", Y_true)\n",
    "writeToFile(\"outputYPred.csv\", Y_pred)\n",
    "\n",
    "Y_true_final = np.array(Y_true).flatten()\n",
    "Y_pred_final = np.array(Y_pred).flatten()\n",
    "\n",
    "print(\"Overall F1\" + classification_report(Y_true_final, Y_pred_final, target_names=labels))\n",
    "\n",
    "Y_evaluate_with_FP = (Y_true_final != 0) + (Y_pred_final != 0)\n",
    "Y_evaluate_without_FP = (Y_true_final != 0)\n",
    "\n",
    "print(\"Without FP \" + classification_report(Y_true[Y_evaluate_without_FP], Y_pred[Y_evaluate_without_FP],\n",
    "                                            target_names=labels))\n",
    "\n",
    "print(\"With False positive (O's predicted as a Entity class) #s are not comparable quiet between models\" +\n",
    "      classification_report(Y_true[Y_evaluate_with_FP], Y_pred[Y_evaluate_with_FP],\n",
    "                            labels=list(range(1, (len(labels) - 1))),\n",
    "                            target_names=[z.replace('I-', '').replace('B-', '') for z in labels if z != 'Others']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
